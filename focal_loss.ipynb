{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c51364f",
   "metadata": {},
   "source": [
    "# catgeorical focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e15207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed alpha weights: [0.08695652335882187, 0.30434781312942505, 0.6086956262588501]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vineela\\AppData\\Local\\Temp\\ipykernel_24244\\1404624113.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  alpha = torch.tensor(alpha, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal Loss: 0.009567061439156532\n",
      "Gradients w.r.t. logits:\n",
      " tensor([[-0.0014,  0.0008,  0.0006],\n",
      "        [ 0.0010, -0.0018,  0.0009],\n",
      "        [ 0.0013,  0.0005, -0.0018],\n",
      "        [ 0.0072, -0.0145,  0.0072]])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Compute class weights (alpha) from class counts\n",
    "# ---------------------------------------------------------------\n",
    "def compute_alpha_from_counts(class_counts):\n",
    "    \"\"\"\n",
    "    Compute normalized inverse frequency class weights.\n",
    "    \n",
    "    Args:\n",
    "        class_counts (Tensor): shape (num_classes,)\n",
    "    \n",
    "    Returns:\n",
    "        alpha (Tensor): shape (num_classes,)\n",
    "    \"\"\"\n",
    "    # Convert to float\n",
    "    counts = class_counts.float()\n",
    "    \n",
    "    # Compute class frequencies\n",
    "    freq = counts / counts.sum()\n",
    "    \n",
    "    # Compute inverse frequencies\n",
    "    inv_freq = 1.0 / freq\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    alpha = inv_freq / inv_freq.sum()\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "# Example class counts\n",
    "class_counts = torch.tensor([700, 200, 100])\n",
    "alpha = compute_alpha_from_counts(class_counts)\n",
    "\n",
    "print(\"Computed alpha weights:\", alpha.tolist())\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Define categorical focal loss class\n",
    "# ---------------------------------------------------------------\n",
    "class CategoricalFocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        \"\"\"\n",
    "        Categorical Focal Loss.\n",
    "\n",
    "        Args:\n",
    "            gamma (float): focusing parameter Î³\n",
    "            alpha (Tensor or None): class weights, shape (num_classes,)\n",
    "                                    if None, no weighting\n",
    "            reduction (str): 'mean', 'sum', or 'none'\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        if alpha is not None:\n",
    "            alpha = torch.tensor(alpha, dtype=torch.float32)\n",
    "            self.register_buffer('alpha', alpha)\n",
    "        else:\n",
    "            self.alpha = None\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        \"\"\"\n",
    "        Compute focal loss.\n",
    "\n",
    "        Args:\n",
    "            logits (Tensor): shape (batch_size, num_classes)\n",
    "            targets (Tensor): shape (batch_size,) with integer class indices\n",
    "\n",
    "        Returns:\n",
    "            loss (Tensor): scalar if reduced, else shape (batch_size,)\n",
    "        \"\"\"\n",
    "        # Compute softmax probabilities\n",
    "        probs = F.softmax(logits, dim=1)  # (batch_size, num_classes)\n",
    "\n",
    "        # Select the probability of the true class\n",
    "        pt = probs[torch.arange(logits.shape[0]), targets]  # (batch_size,)\n",
    "\n",
    "        # Compute the modulating factor (1 - pt)^gamma\n",
    "        focal_factor = (1.0 - pt) ** self.gamma\n",
    "\n",
    "        # Compute log(pt)\n",
    "        log_pt = torch.log(pt + 1e-9)\n",
    "\n",
    "        # Basic focal loss\n",
    "        loss = - focal_factor * log_pt\n",
    "\n",
    "        # Apply class weights if given\n",
    "        if self.alpha is not None:\n",
    "            at = self.alpha[targets]  # gather alpha weight per example\n",
    "            loss = at * loss\n",
    "\n",
    "        # Reduce\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Dummy test example\n",
    "# ---------------------------------------------------------------\n",
    "# Dummy logits from a model (batch_size=4, num_classes=3)\n",
    "logits = torch.tensor([\n",
    "    [2.0, 0.5, 0.3],\n",
    "    [0.2, 2.2, 0.1],\n",
    "    [1.0, 0.1, 3.0],\n",
    "    [0.5, 1.5, 0.5]\n",
    "], requires_grad=True)\n",
    "\n",
    "# True class labels\n",
    "targets = torch.tensor([0, 1, 2, 1])\n",
    "\n",
    "# Create focal loss criterion\n",
    "criterion = CategoricalFocalLoss(\n",
    "    gamma=2.0,\n",
    "    alpha=alpha,\n",
    "    reduction='mean'\n",
    ")\n",
    "\n",
    "# Compute loss\n",
    "loss = criterion(logits, targets)\n",
    "print(\"Focal Loss:\", loss.item())\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "# Check gradients\n",
    "print(\"Gradients w.r.t. logits:\\n\", logits.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff8bce2",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b630461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
